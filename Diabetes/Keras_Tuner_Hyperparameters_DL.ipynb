{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Keras Tuner Hyperparameters"],"metadata":{"id":"ecP1P8x0pePT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"e7i4dwlJpaAm","outputId":"90e6ed79-c1f6-459c-af4f-676bcaebb973"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n","0             6      148             72             35        0  33.6   \n","1             1       85             66             29        0  26.6   \n","2             8      183             64              0        0  23.3   \n","3             1       89             66             23       94  28.1   \n","4             0      137             40             35      168  43.1   \n","5             5      116             74              0        0  25.6   \n","6             3       78             50             32       88  31.0   \n","7            10      115              0              0        0  35.3   \n","8             2      197             70             45      543  30.5   \n","9             8      125             96              0        0   0.0   \n","10            4      110             92              0        0  37.6   \n","11           10      168             74              0        0  38.0   \n","12           10      139             80              0        0  27.1   \n","13            1      189             60             23      846  30.1   \n","14            5      166             72             19      175  25.8   \n","15            7      100              0              0        0  30.0   \n","16            0      118             84             47      230  45.8   \n","17            7      107             74              0        0  29.6   \n","18            1      103             30             38       83  43.3   \n","19            1      115             70             30       96  34.6   \n","\n","    DiabetesPedigreeFunction  Age  Outcome  \n","0                      0.627   50        1  \n","1                      0.351   31        0  \n","2                      0.672   32        1  \n","3                      0.167   21        0  \n","4                      2.288   33        1  \n","5                      0.201   30        0  \n","6                      0.248   26        1  \n","7                      0.134   29        0  \n","8                      0.158   53        1  \n","9                      0.232   54        1  \n","10                     0.191   30        0  \n","11                     0.537   34        1  \n","12                     1.441   57        0  \n","13                     0.398   59        1  \n","14                     0.587   51        1  \n","15                     0.484   32        1  \n","16                     0.551   31        1  \n","17                     0.254   31        1  \n","18                     0.183   33        0  \n","19                     0.529   32        1  "],"text/html":["\n","  <div id=\"df-5acfa420-551a-46b4-8f7d-3d9c929923b4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>116</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>25.6</td>\n","      <td>0.201</td>\n","      <td>30</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3</td>\n","      <td>78</td>\n","      <td>50</td>\n","      <td>32</td>\n","      <td>88</td>\n","      <td>31.0</td>\n","      <td>0.248</td>\n","      <td>26</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>10</td>\n","      <td>115</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35.3</td>\n","      <td>0.134</td>\n","      <td>29</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>197</td>\n","      <td>70</td>\n","      <td>45</td>\n","      <td>543</td>\n","      <td>30.5</td>\n","      <td>0.158</td>\n","      <td>53</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>8</td>\n","      <td>125</td>\n","      <td>96</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.232</td>\n","      <td>54</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>4</td>\n","      <td>110</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>37.6</td>\n","      <td>0.191</td>\n","      <td>30</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>10</td>\n","      <td>168</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>0.537</td>\n","      <td>34</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>10</td>\n","      <td>139</td>\n","      <td>80</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>27.1</td>\n","      <td>1.441</td>\n","      <td>57</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>189</td>\n","      <td>60</td>\n","      <td>23</td>\n","      <td>846</td>\n","      <td>30.1</td>\n","      <td>0.398</td>\n","      <td>59</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>5</td>\n","      <td>166</td>\n","      <td>72</td>\n","      <td>19</td>\n","      <td>175</td>\n","      <td>25.8</td>\n","      <td>0.587</td>\n","      <td>51</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>7</td>\n","      <td>100</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>30.0</td>\n","      <td>0.484</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0</td>\n","      <td>118</td>\n","      <td>84</td>\n","      <td>47</td>\n","      <td>230</td>\n","      <td>45.8</td>\n","      <td>0.551</td>\n","      <td>31</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>7</td>\n","      <td>107</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>29.6</td>\n","      <td>0.254</td>\n","      <td>31</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1</td>\n","      <td>103</td>\n","      <td>30</td>\n","      <td>38</td>\n","      <td>83</td>\n","      <td>43.3</td>\n","      <td>0.183</td>\n","      <td>33</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1</td>\n","      <td>115</td>\n","      <td>70</td>\n","      <td>30</td>\n","      <td>96</td>\n","      <td>34.6</td>\n","      <td>0.529</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5acfa420-551a-46b4-8f7d-3d9c929923b4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5acfa420-551a-46b4-8f7d-3d9c929923b4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5acfa420-551a-46b4-8f7d-3d9c929923b4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["import os, sys\n","import numpy as np\n","import pandas as pd\n","df = pd.read_csv('/content/diabetes.csv')\n","df.head(20)"]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dvP1QyuAqKOu","outputId":"811351dd-f883-4e95-ad4a-9e32eac49cff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pregnancies                 0\n","Glucose                     0\n","BloodPressure               0\n","SkinThickness               0\n","Insulin                     0\n","BMI                         0\n","DiabetesPedigreeFunction    0\n","Age                         0\n","Outcome                     0\n","dtype: int64"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"IqiDtDgVqQgd","outputId":"bfef78c7-6941-4322-a694-eb0a99dd8c43"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n","count   768.000000  768.000000     768.000000     768.000000  768.000000   \n","mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n","std       3.369578   31.972618      19.355807      15.952218  115.244002   \n","min       0.000000    0.000000       0.000000       0.000000    0.000000   \n","25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n","50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n","75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n","max      17.000000  199.000000     122.000000      99.000000  846.000000   \n","\n","              BMI  DiabetesPedigreeFunction         Age     Outcome  \n","count  768.000000                768.000000  768.000000  768.000000  \n","mean    31.992578                  0.471876   33.240885    0.348958  \n","std      7.884160                  0.331329   11.760232    0.476951  \n","min      0.000000                  0.078000   21.000000    0.000000  \n","25%     27.300000                  0.243750   24.000000    0.000000  \n","50%     32.000000                  0.372500   29.000000    0.000000  \n","75%     36.600000                  0.626250   41.000000    1.000000  \n","max     67.100000                  2.420000   81.000000    1.000000  "],"text/html":["\n","  <div id=\"df-d5554afd-b65e-4b2e-943b-f8ec53fd10a4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>3.845052</td>\n","      <td>120.894531</td>\n","      <td>69.105469</td>\n","      <td>20.536458</td>\n","      <td>79.799479</td>\n","      <td>31.992578</td>\n","      <td>0.471876</td>\n","      <td>33.240885</td>\n","      <td>0.348958</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>3.369578</td>\n","      <td>31.972618</td>\n","      <td>19.355807</td>\n","      <td>15.952218</td>\n","      <td>115.244002</td>\n","      <td>7.884160</td>\n","      <td>0.331329</td>\n","      <td>11.760232</td>\n","      <td>0.476951</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.078000</td>\n","      <td>21.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.000000</td>\n","      <td>99.000000</td>\n","      <td>62.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>27.300000</td>\n","      <td>0.243750</td>\n","      <td>24.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>3.000000</td>\n","      <td>117.000000</td>\n","      <td>72.000000</td>\n","      <td>23.000000</td>\n","      <td>30.500000</td>\n","      <td>32.000000</td>\n","      <td>0.372500</td>\n","      <td>29.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>6.000000</td>\n","      <td>140.250000</td>\n","      <td>80.000000</td>\n","      <td>32.000000</td>\n","      <td>127.250000</td>\n","      <td>36.600000</td>\n","      <td>0.626250</td>\n","      <td>41.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>17.000000</td>\n","      <td>199.000000</td>\n","      <td>122.000000</td>\n","      <td>99.000000</td>\n","      <td>846.000000</td>\n","      <td>67.100000</td>\n","      <td>2.420000</td>\n","      <td>81.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5554afd-b65e-4b2e-943b-f8ec53fd10a4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d5554afd-b65e-4b2e-943b-f8ec53fd10a4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d5554afd-b65e-4b2e-943b-f8ec53fd10a4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["df['Glucose'].median()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"glBe9UoPqaHs","outputId":"da141802-c20c-4263-d88b-5356bc282616"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["117.0"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df['Glucose'] = np.where(df['Glucose']==0,df['Glucose'].median(), df['Glucose'])\n","df['BloodPressure'] = np.where(df['BloodPressure']==0,df['BloodPressure'].median(), df['BloodPressure'])\n","df['SkinThickness'] = np.where(df['SkinThickness']==0,df['SkinThickness'].median(), df['SkinThickness'])\n","df['Insulin'] = np.where(df['Insulin']==0,df['Insulin'].median(), df['Insulin'])\n","df['BMI'] = np.where(df['BMI']==0,df['BMI'].median(), df['BMI'])"],"metadata":{"id":"bLByk2Z0pjTw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"Q2LTRuU_pjXw","outputId":"f5b2af91-94c1-4321-e54a-9b3d2928e809"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n","count   768.000000  768.000000     768.000000     768.000000  768.000000   \n","mean      3.845052  121.656250      72.386719      27.334635   94.652344   \n","std       3.369578   30.438286      12.096642       9.229014  105.547598   \n","min       0.000000   44.000000      24.000000       7.000000   14.000000   \n","25%       1.000000   99.750000      64.000000      23.000000   30.500000   \n","50%       3.000000  117.000000      72.000000      23.000000   31.250000   \n","75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n","max      17.000000  199.000000     122.000000      99.000000  846.000000   \n","\n","              BMI  DiabetesPedigreeFunction         Age     Outcome  \n","count  768.000000                768.000000  768.000000  768.000000  \n","mean    32.450911                  0.471876   33.240885    0.348958  \n","std      6.875366                  0.331329   11.760232    0.476951  \n","min     18.200000                  0.078000   21.000000    0.000000  \n","25%     27.500000                  0.243750   24.000000    0.000000  \n","50%     32.000000                  0.372500   29.000000    0.000000  \n","75%     36.600000                  0.626250   41.000000    1.000000  \n","max     67.100000                  2.420000   81.000000    1.000000  "],"text/html":["\n","  <div id=\"df-ff2f8046-f70b-4d53-9fbd-20306de7f107\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>3.845052</td>\n","      <td>121.656250</td>\n","      <td>72.386719</td>\n","      <td>27.334635</td>\n","      <td>94.652344</td>\n","      <td>32.450911</td>\n","      <td>0.471876</td>\n","      <td>33.240885</td>\n","      <td>0.348958</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>3.369578</td>\n","      <td>30.438286</td>\n","      <td>12.096642</td>\n","      <td>9.229014</td>\n","      <td>105.547598</td>\n","      <td>6.875366</td>\n","      <td>0.331329</td>\n","      <td>11.760232</td>\n","      <td>0.476951</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>44.000000</td>\n","      <td>24.000000</td>\n","      <td>7.000000</td>\n","      <td>14.000000</td>\n","      <td>18.200000</td>\n","      <td>0.078000</td>\n","      <td>21.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.000000</td>\n","      <td>99.750000</td>\n","      <td>64.000000</td>\n","      <td>23.000000</td>\n","      <td>30.500000</td>\n","      <td>27.500000</td>\n","      <td>0.243750</td>\n","      <td>24.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>3.000000</td>\n","      <td>117.000000</td>\n","      <td>72.000000</td>\n","      <td>23.000000</td>\n","      <td>31.250000</td>\n","      <td>32.000000</td>\n","      <td>0.372500</td>\n","      <td>29.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>6.000000</td>\n","      <td>140.250000</td>\n","      <td>80.000000</td>\n","      <td>32.000000</td>\n","      <td>127.250000</td>\n","      <td>36.600000</td>\n","      <td>0.626250</td>\n","      <td>41.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>17.000000</td>\n","      <td>199.000000</td>\n","      <td>122.000000</td>\n","      <td>99.000000</td>\n","      <td>846.000000</td>\n","      <td>67.100000</td>\n","      <td>2.420000</td>\n","      <td>81.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff2f8046-f70b-4d53-9fbd-20306de7f107')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ff2f8046-f70b-4d53-9fbd-20306de7f107 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ff2f8046-f70b-4d53-9fbd-20306de7f107');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["x = df.iloc[:,:-1].values\n","y = df.iloc[:,-1].values"],"metadata":{"id":"KdPhIHfLpjbO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x = scaler.fit_transform(x)"],"metadata":{"id":"0bI7lOAwsK-U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"],"metadata":{"id":"XE5bKslTsjhG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Building Deep Neural Network "],"metadata":{"id":"CfFH09GXs7iS"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import Sequential\n","from keras.layers import Dense, Flatten, Dropout, BatchNormalization"],"metadata":{"id":"ZBcyvFhpsylv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# General Method\n","model = Sequential()\n","model.add(Dense(32, activation='relu', input_dim = 8))\n","model.add(BatchNormalization())\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"e7_P3HScsqov"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"km5jWPBZsd6v","outputId":"4def5181-5873-4c8d-caa0-6abe4bb977b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 32)                288       \n","                                                                 \n"," batch_normalization (BatchN  (None, 32)               128       \n"," ormalization)                                                   \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 449\n","Trainable params: 385\n","Non-trainable params: 64\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=32, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XA2jS86Jtrzr","outputId":"859bced4-650e-48cd-d9fe-f354f543cc7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","20/20 [==============================] - 1s 13ms/step - loss: 0.7178 - accuracy: 0.4625 - val_loss: 0.6518 - val_accuracy: 0.5974\n","Epoch 2/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6401 - val_loss: 0.5904 - val_accuracy: 0.7208\n","Epoch 3/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.7117 - val_loss: 0.5461 - val_accuracy: 0.7597\n","Epoch 4/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7329 - val_loss: 0.5150 - val_accuracy: 0.7857\n","Epoch 5/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7394 - val_loss: 0.4905 - val_accuracy: 0.7857\n","Epoch 6/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7476 - val_loss: 0.4741 - val_accuracy: 0.7987\n","Epoch 7/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7557 - val_loss: 0.4611 - val_accuracy: 0.7922\n","Epoch 8/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7541 - val_loss: 0.4525 - val_accuracy: 0.7857\n","Epoch 9/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7606 - val_loss: 0.4446 - val_accuracy: 0.7727\n","Epoch 10/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7638 - val_loss: 0.4397 - val_accuracy: 0.7857\n","Epoch 11/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7655 - val_loss: 0.4347 - val_accuracy: 0.7922\n","Epoch 12/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7687 - val_loss: 0.4314 - val_accuracy: 0.7857\n","Epoch 13/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7736 - val_loss: 0.4290 - val_accuracy: 0.7792\n","Epoch 14/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7736 - val_loss: 0.4282 - val_accuracy: 0.7792\n","Epoch 15/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7736 - val_loss: 0.4263 - val_accuracy: 0.7727\n","Epoch 16/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7769 - val_loss: 0.4244 - val_accuracy: 0.7857\n","Epoch 17/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7785 - val_loss: 0.4233 - val_accuracy: 0.7857\n","Epoch 18/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7801 - val_loss: 0.4230 - val_accuracy: 0.7792\n","Epoch 19/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7834 - val_loss: 0.4216 - val_accuracy: 0.7792\n","Epoch 20/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7834 - val_loss: 0.4207 - val_accuracy: 0.7922\n","Epoch 21/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7850 - val_loss: 0.4194 - val_accuracy: 0.7922\n","Epoch 22/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7899 - val_loss: 0.4186 - val_accuracy: 0.7922\n","Epoch 23/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7866 - val_loss: 0.4179 - val_accuracy: 0.7922\n","Epoch 24/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7866 - val_loss: 0.4169 - val_accuracy: 0.7922\n","Epoch 25/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7834 - val_loss: 0.4163 - val_accuracy: 0.7922\n","Epoch 26/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7850 - val_loss: 0.4172 - val_accuracy: 0.7922\n","Epoch 27/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7834 - val_loss: 0.4160 - val_accuracy: 0.7922\n","Epoch 28/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7818 - val_loss: 0.4154 - val_accuracy: 0.7922\n","Epoch 29/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7883 - val_loss: 0.4141 - val_accuracy: 0.7922\n","Epoch 30/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7834 - val_loss: 0.4148 - val_accuracy: 0.7987\n","Epoch 31/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7850 - val_loss: 0.4138 - val_accuracy: 0.7987\n","Epoch 32/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7834 - val_loss: 0.4134 - val_accuracy: 0.7987\n","Epoch 33/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7850 - val_loss: 0.4130 - val_accuracy: 0.7987\n","Epoch 34/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7866 - val_loss: 0.4134 - val_accuracy: 0.7987\n","Epoch 35/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7866 - val_loss: 0.4124 - val_accuracy: 0.7987\n","Epoch 36/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7850 - val_loss: 0.4115 - val_accuracy: 0.8052\n","Epoch 37/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7899 - val_loss: 0.4112 - val_accuracy: 0.7987\n","Epoch 38/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7883 - val_loss: 0.4109 - val_accuracy: 0.7922\n","Epoch 39/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7883 - val_loss: 0.4111 - val_accuracy: 0.7987\n","Epoch 40/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7866 - val_loss: 0.4108 - val_accuracy: 0.7987\n","Epoch 41/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7883 - val_loss: 0.4104 - val_accuracy: 0.7987\n","Epoch 42/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.4103 - val_accuracy: 0.7987\n","Epoch 43/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.4111 - val_accuracy: 0.7987\n","Epoch 44/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7915 - val_loss: 0.4112 - val_accuracy: 0.7987\n","Epoch 45/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.4096 - val_accuracy: 0.7987\n","Epoch 46/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7932 - val_loss: 0.4092 - val_accuracy: 0.7987\n","Epoch 47/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7932 - val_loss: 0.4086 - val_accuracy: 0.7987\n","Epoch 48/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7932 - val_loss: 0.4089 - val_accuracy: 0.7987\n","Epoch 49/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7932 - val_loss: 0.4089 - val_accuracy: 0.7987\n","Epoch 50/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7948 - val_loss: 0.4095 - val_accuracy: 0.7987\n","Epoch 51/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7948 - val_loss: 0.4086 - val_accuracy: 0.7987\n","Epoch 52/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7948 - val_loss: 0.4075 - val_accuracy: 0.7987\n","Epoch 53/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7948 - val_loss: 0.4083 - val_accuracy: 0.7987\n","Epoch 54/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7980 - val_loss: 0.4082 - val_accuracy: 0.7987\n","Epoch 55/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7948 - val_loss: 0.4081 - val_accuracy: 0.7987\n","Epoch 56/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7932 - val_loss: 0.4083 - val_accuracy: 0.8052\n","Epoch 57/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7948 - val_loss: 0.4087 - val_accuracy: 0.8052\n","Epoch 58/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7932 - val_loss: 0.4076 - val_accuracy: 0.7987\n","Epoch 59/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7964 - val_loss: 0.4076 - val_accuracy: 0.7987\n","Epoch 60/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7964 - val_loss: 0.4072 - val_accuracy: 0.7987\n","Epoch 61/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7964 - val_loss: 0.4065 - val_accuracy: 0.7987\n","Epoch 62/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7980 - val_loss: 0.4067 - val_accuracy: 0.8052\n","Epoch 63/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7964 - val_loss: 0.4061 - val_accuracy: 0.8052\n","Epoch 64/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7964 - val_loss: 0.4063 - val_accuracy: 0.8052\n","Epoch 65/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7964 - val_loss: 0.4068 - val_accuracy: 0.7987\n","Epoch 66/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7964 - val_loss: 0.4066 - val_accuracy: 0.7987\n","Epoch 67/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7932 - val_loss: 0.4062 - val_accuracy: 0.8052\n","Epoch 68/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8013 - val_loss: 0.4063 - val_accuracy: 0.8052\n","Epoch 69/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7980 - val_loss: 0.4062 - val_accuracy: 0.7987\n","Epoch 70/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7964 - val_loss: 0.4056 - val_accuracy: 0.7987\n","Epoch 71/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7948 - val_loss: 0.4060 - val_accuracy: 0.8052\n","Epoch 72/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7948 - val_loss: 0.4060 - val_accuracy: 0.8052\n","Epoch 73/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7964 - val_loss: 0.4057 - val_accuracy: 0.7987\n","Epoch 74/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7997 - val_loss: 0.4057 - val_accuracy: 0.7987\n","Epoch 75/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7997 - val_loss: 0.4072 - val_accuracy: 0.8052\n","Epoch 76/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7964 - val_loss: 0.4063 - val_accuracy: 0.7987\n","Epoch 77/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.7980 - val_loss: 0.4062 - val_accuracy: 0.7922\n","Epoch 78/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.7964 - val_loss: 0.4045 - val_accuracy: 0.8052\n","Epoch 79/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.7980 - val_loss: 0.4054 - val_accuracy: 0.7987\n","Epoch 80/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.7948 - val_loss: 0.4069 - val_accuracy: 0.7987\n","Epoch 81/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.7997 - val_loss: 0.4060 - val_accuracy: 0.7987\n","Epoch 82/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.7997 - val_loss: 0.4045 - val_accuracy: 0.8052\n","Epoch 83/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.7997 - val_loss: 0.4047 - val_accuracy: 0.8052\n","Epoch 84/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8046 - val_loss: 0.4048 - val_accuracy: 0.7922\n","Epoch 85/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8029 - val_loss: 0.4043 - val_accuracy: 0.7922\n","Epoch 86/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8013 - val_loss: 0.4040 - val_accuracy: 0.7922\n","Epoch 87/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8046 - val_loss: 0.4049 - val_accuracy: 0.7922\n","Epoch 88/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8013 - val_loss: 0.4047 - val_accuracy: 0.7922\n","Epoch 89/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8046 - val_loss: 0.4047 - val_accuracy: 0.7922\n","Epoch 90/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8046 - val_loss: 0.4055 - val_accuracy: 0.7922\n","Epoch 91/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8029 - val_loss: 0.4044 - val_accuracy: 0.7922\n","Epoch 92/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8029 - val_loss: 0.4045 - val_accuracy: 0.7987\n","Epoch 93/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8078 - val_loss: 0.4046 - val_accuracy: 0.8052\n","Epoch 94/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8029 - val_loss: 0.4041 - val_accuracy: 0.8052\n","Epoch 95/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8013 - val_loss: 0.4046 - val_accuracy: 0.8117\n","Epoch 96/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8013 - val_loss: 0.4037 - val_accuracy: 0.8052\n","Epoch 97/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8062 - val_loss: 0.4036 - val_accuracy: 0.8052\n","Epoch 98/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8029 - val_loss: 0.4024 - val_accuracy: 0.8052\n","Epoch 99/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8013 - val_loss: 0.4031 - val_accuracy: 0.8052\n","Epoch 100/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8046 - val_loss: 0.4033 - val_accuracy: 0.7987\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2aa0226070>"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# manual approach : loss: 0.4082 - accuracy: 0.8046 - val_loss: 0.4033 - val_accuracy: 0.7987"],"metadata":{"id":"tHDukUP7pjeL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1) How to select appropriate optimizer\n","# 2) How to select no. of nodes in a layers\n","# 3) How to select no. of layers \n","# 4) All in All - one model"],"metadata":{"id":"5vjTuZVHt80D"}},{"cell_type":"markdown","source":["# Keras Tuning"],"metadata":{"id":"Uav0tR8euScy"}},{"cell_type":"code","source":["!pip install keras-tuner --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8OooRvepjhV","outputId":"30a470b6-1147-40da-edf7-d6439ea474df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-tuner\n","  Downloading keras_tuner-1.3.0-py3-none-any.whl (167 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kt-legacy\n","  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (23.0)\n","Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.11.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n","Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.31.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n","Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.22.4)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.2.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n","Installing collected packages: kt-legacy, jedi, keras-tuner\n","Successfully installed jedi-0.18.2 keras-tuner-1.3.0 kt-legacy-1.0.4\n"]}]},{"cell_type":"code","source":["import keras_tuner as kt"],"metadata":{"id":"vtu3lf1npjj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_model(hp):\n","  model1 = Sequential()\n","  model1.add(Dense(32, activation='relu', input_dim = 8))\n","  model1.add(Dense(1, activation='sigmoid'))\n","  optimizer = hp.Choice('optimizer', values=['adam', 'sgd','rmsprop', 'adagrad','adadelta'])\n","  model1.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","  return model1"],"metadata":{"id":"o5uS-5T2pjqm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Best Optimizer - we have to find\n","\n","tuner = kt.RandomSearch(\n","    build_model,\n","    objective='val_accuracy',\n","    max_trials=5)"],"metadata":{"id":"w39eofLjpjtz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner.search(x_train, y_train, validation_data=(x_test, y_test), epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TbI9LtdpjxU","outputId":"d9039f1b-380d-4eb4-9ce5-9ddad93da994"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 5 Complete [00h 00m 02s]\n","val_accuracy: 0.5844155550003052\n","\n","Best val_accuracy So Far: 0.8116883039474487\n","Total elapsed time: 00h 00m 08s\n"]}]},{"cell_type":"code","source":["tuner.get_best_hyperparameters()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"maRMqIV-pj0U","outputId":"6e72dfb4-8b9e-4113-a985-82ce7b8b3073"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters at 0x7f2a93cd7460>]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["tuner.get_best_hyperparameters()[0].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MXngxUiwtme","outputId":"6a2817f0-23f8-40f4-90da-eb3305c298a5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'optimizer': 'rmsprop'}"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["model = tuner.get_best_models(num_models=1)[0]"],"metadata":{"id":"LpWSMa4qpj3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fSUVRekCxDPy","outputId":"d97357e1-0ac7-4292-cfe9-e52ce7f0f02c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 32)                288       \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 321\n","Trainable params: 321\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.fit(x_train, y_train, batch_size=32, epochs=100, initial_epoch=6, validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1tnvYIpgxEky","outputId":"ddc8439a-5175-4ace-944d-7e6ba3ce8b44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 7/100\n","20/20 [==============================] - 1s 10ms/step - loss: 0.5055 - accuracy: 0.7459 - val_loss: 0.4654 - val_accuracy: 0.8182\n","Epoch 8/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7557 - val_loss: 0.4553 - val_accuracy: 0.8182\n","Epoch 9/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7704 - val_loss: 0.4486 - val_accuracy: 0.8117\n","Epoch 10/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7736 - val_loss: 0.4425 - val_accuracy: 0.8182\n","Epoch 11/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7687 - val_loss: 0.4382 - val_accuracy: 0.8052\n","Epoch 12/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7785 - val_loss: 0.4350 - val_accuracy: 0.7922\n","Epoch 13/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7752 - val_loss: 0.4315 - val_accuracy: 0.7922\n","Epoch 14/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7801 - val_loss: 0.4281 - val_accuracy: 0.7857\n","Epoch 15/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7785 - val_loss: 0.4265 - val_accuracy: 0.7857\n","Epoch 16/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7785 - val_loss: 0.4248 - val_accuracy: 0.7857\n","Epoch 17/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7818 - val_loss: 0.4235 - val_accuracy: 0.7922\n","Epoch 18/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7704 - val_loss: 0.4221 - val_accuracy: 0.7922\n","Epoch 19/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7704 - val_loss: 0.4210 - val_accuracy: 0.7922\n","Epoch 20/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7736 - val_loss: 0.4200 - val_accuracy: 0.7857\n","Epoch 21/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7752 - val_loss: 0.4190 - val_accuracy: 0.7857\n","Epoch 22/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7752 - val_loss: 0.4179 - val_accuracy: 0.7922\n","Epoch 23/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7752 - val_loss: 0.4171 - val_accuracy: 0.7922\n","Epoch 24/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7769 - val_loss: 0.4169 - val_accuracy: 0.7922\n","Epoch 25/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7769 - val_loss: 0.4170 - val_accuracy: 0.7922\n","Epoch 26/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7752 - val_loss: 0.4165 - val_accuracy: 0.7987\n","Epoch 27/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7752 - val_loss: 0.4154 - val_accuracy: 0.8117\n","Epoch 28/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7769 - val_loss: 0.4146 - val_accuracy: 0.8052\n","Epoch 29/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7752 - val_loss: 0.4149 - val_accuracy: 0.8052\n","Epoch 30/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7785 - val_loss: 0.4146 - val_accuracy: 0.8052\n","Epoch 31/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7769 - val_loss: 0.4148 - val_accuracy: 0.8052\n","Epoch 32/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7769 - val_loss: 0.4144 - val_accuracy: 0.8052\n","Epoch 33/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7752 - val_loss: 0.4143 - val_accuracy: 0.7987\n","Epoch 34/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7769 - val_loss: 0.4150 - val_accuracy: 0.7922\n","Epoch 35/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7785 - val_loss: 0.4148 - val_accuracy: 0.7922\n","Epoch 36/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7818 - val_loss: 0.4148 - val_accuracy: 0.7922\n","Epoch 37/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7818 - val_loss: 0.4140 - val_accuracy: 0.7922\n","Epoch 38/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7801 - val_loss: 0.4144 - val_accuracy: 0.7922\n","Epoch 39/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7818 - val_loss: 0.4132 - val_accuracy: 0.7922\n","Epoch 40/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7818 - val_loss: 0.4127 - val_accuracy: 0.7922\n","Epoch 41/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7801 - val_loss: 0.4131 - val_accuracy: 0.7922\n","Epoch 42/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7818 - val_loss: 0.4133 - val_accuracy: 0.7922\n","Epoch 43/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7818 - val_loss: 0.4130 - val_accuracy: 0.7922\n","Epoch 44/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7834 - val_loss: 0.4118 - val_accuracy: 0.7922\n","Epoch 45/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7834 - val_loss: 0.4119 - val_accuracy: 0.7922\n","Epoch 46/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7850 - val_loss: 0.4118 - val_accuracy: 0.7922\n","Epoch 47/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7850 - val_loss: 0.4113 - val_accuracy: 0.7922\n","Epoch 48/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7866 - val_loss: 0.4108 - val_accuracy: 0.7987\n","Epoch 49/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7866 - val_loss: 0.4099 - val_accuracy: 0.7987\n","Epoch 50/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7899 - val_loss: 0.4095 - val_accuracy: 0.7987\n","Epoch 51/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7899 - val_loss: 0.4094 - val_accuracy: 0.7987\n","Epoch 52/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7866 - val_loss: 0.4093 - val_accuracy: 0.7922\n","Epoch 53/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7850 - val_loss: 0.4100 - val_accuracy: 0.7922\n","Epoch 54/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7948 - val_loss: 0.4099 - val_accuracy: 0.7922\n","Epoch 55/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7883 - val_loss: 0.4095 - val_accuracy: 0.7922\n","Epoch 56/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7866 - val_loss: 0.4093 - val_accuracy: 0.7922\n","Epoch 57/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7883 - val_loss: 0.4088 - val_accuracy: 0.7922\n","Epoch 58/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7915 - val_loss: 0.4088 - val_accuracy: 0.7922\n","Epoch 59/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7834 - val_loss: 0.4084 - val_accuracy: 0.7922\n","Epoch 60/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7850 - val_loss: 0.4082 - val_accuracy: 0.7922\n","Epoch 61/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7866 - val_loss: 0.4082 - val_accuracy: 0.7922\n","Epoch 62/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7850 - val_loss: 0.4083 - val_accuracy: 0.7922\n","Epoch 63/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7915 - val_loss: 0.4084 - val_accuracy: 0.7922\n","Epoch 64/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7932 - val_loss: 0.4075 - val_accuracy: 0.7987\n","Epoch 65/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.4071 - val_accuracy: 0.7987\n","Epoch 66/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7964 - val_loss: 0.4070 - val_accuracy: 0.8052\n","Epoch 67/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.4072 - val_accuracy: 0.7987\n","Epoch 68/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7980 - val_loss: 0.4079 - val_accuracy: 0.8052\n","Epoch 69/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7980 - val_loss: 0.4070 - val_accuracy: 0.7987\n","Epoch 70/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7948 - val_loss: 0.4074 - val_accuracy: 0.8052\n","Epoch 71/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7866 - val_loss: 0.4075 - val_accuracy: 0.8052\n","Epoch 72/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7932 - val_loss: 0.4071 - val_accuracy: 0.8052\n","Epoch 73/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7883 - val_loss: 0.4065 - val_accuracy: 0.8052\n","Epoch 74/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7964 - val_loss: 0.4063 - val_accuracy: 0.8052\n","Epoch 75/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7915 - val_loss: 0.4063 - val_accuracy: 0.7987\n","Epoch 76/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7964 - val_loss: 0.4058 - val_accuracy: 0.7987\n","Epoch 77/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7948 - val_loss: 0.4054 - val_accuracy: 0.7987\n","Epoch 78/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7964 - val_loss: 0.4047 - val_accuracy: 0.8052\n","Epoch 79/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7948 - val_loss: 0.4049 - val_accuracy: 0.8117\n","Epoch 80/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7932 - val_loss: 0.4045 - val_accuracy: 0.8052\n","Epoch 81/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7964 - val_loss: 0.4038 - val_accuracy: 0.8052\n","Epoch 82/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7980 - val_loss: 0.4045 - val_accuracy: 0.8052\n","Epoch 83/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7948 - val_loss: 0.4044 - val_accuracy: 0.7987\n","Epoch 84/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7948 - val_loss: 0.4046 - val_accuracy: 0.7987\n","Epoch 85/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7964 - val_loss: 0.4044 - val_accuracy: 0.8052\n","Epoch 86/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7964 - val_loss: 0.4045 - val_accuracy: 0.8052\n","Epoch 87/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7964 - val_loss: 0.4044 - val_accuracy: 0.8117\n","Epoch 88/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7997 - val_loss: 0.4050 - val_accuracy: 0.8052\n","Epoch 89/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7980 - val_loss: 0.4050 - val_accuracy: 0.8117\n","Epoch 90/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7948 - val_loss: 0.4048 - val_accuracy: 0.8117\n","Epoch 91/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8013 - val_loss: 0.4040 - val_accuracy: 0.8117\n","Epoch 92/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7964 - val_loss: 0.4039 - val_accuracy: 0.8117\n","Epoch 93/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7948 - val_loss: 0.4037 - val_accuracy: 0.8117\n","Epoch 94/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8013 - val_loss: 0.4034 - val_accuracy: 0.8117\n","Epoch 95/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8046 - val_loss: 0.4042 - val_accuracy: 0.8117\n","Epoch 96/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.7899 - val_loss: 0.4040 - val_accuracy: 0.8117\n","Epoch 97/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.7932 - val_loss: 0.4032 - val_accuracy: 0.8117\n","Epoch 98/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7948 - val_loss: 0.4032 - val_accuracy: 0.8117\n","Epoch 99/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7980 - val_loss: 0.4032 - val_accuracy: 0.8052\n","Epoch 100/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7964 - val_loss: 0.4034 - val_accuracy: 0.8117\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2a93470430>"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["# Optimization - rmsprop : loss: 0.4172 - accuracy: 0.7964 - val_loss: 0.4034 - val_accuracy: 0.8117"],"metadata":{"id":"tScgjcxtpj63"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# find the right numbers of neurons in the given layers - Hyperparameters"],"metadata":{"id":"6nSoh6ysx1oM"}},{"cell_type":"code","source":["def build_model(hp):\n","   model = Sequential()\n","   units = hp.Int('units', 8,128, step=8)\n","   # 8 - lower limit\n","   # 128 - upper limit\n","   # step - 8\n","   model.add(Dense(units=units, activation='relu', input_dim = 8))\n","   model.add(Dense(1, activation='sigmoid'))\n","   model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) \n","   return model"],"metadata":{"id":"V9-7fdrfpj9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner = kt.RandomSearch(\n","    build_model,\n","    objective='val_accuracy',\n","    max_trials=5, directory='my_dir', project_name='own_hyperparameter')"],"metadata":{"id":"a_fdcggopkBc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner.search(x_train, y_train, validation_data=(x_test, y_test), epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UnrMK7lJpkEu","outputId":"b314c87f-9ed0-42f9-d68a-ee6c34581cac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 5 Complete [00h 00m 01s]\n","val_accuracy: 0.8051947951316833\n","\n","Best val_accuracy So Far: 0.8051947951316833\n","Total elapsed time: 00h 00m 07s\n"]}]},{"cell_type":"code","source":["tuner.get_best_hyperparameters()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4XAXHNxkpkHy","outputId":"673d08bd-c98a-4ae8-f2ba-cdd10548d06c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters at 0x7f2b00b87af0>]"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["tuner.get_best_hyperparameters()[0].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fViTB0OzzVW7","outputId":"793d4280-d634-4f53-d5f5-9b84310feb9c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'units': 56}"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["model = tuner.get_best_models(num_models=1)[0]"],"metadata":{"id":"i_NWE2HjzX98"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(x_train, y_train, batch_size=32, epochs=100, initial_epoch=6, validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hlBJkpmrzj20","outputId":"3acf882b-4f23-4d04-a43b-fe6788883da4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 7/100\n","20/20 [==============================] - 1s 10ms/step - loss: 0.5369 - accuracy: 0.7410 - val_loss: 0.4893 - val_accuracy: 0.7922\n","Epoch 8/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7508 - val_loss: 0.4720 - val_accuracy: 0.7857\n","Epoch 9/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7557 - val_loss: 0.4596 - val_accuracy: 0.7792\n","Epoch 10/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7622 - val_loss: 0.4475 - val_accuracy: 0.7792\n","Epoch 11/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7655 - val_loss: 0.4408 - val_accuracy: 0.7727\n","Epoch 12/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7622 - val_loss: 0.4342 - val_accuracy: 0.7662\n","Epoch 13/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7590 - val_loss: 0.4299 - val_accuracy: 0.7662\n","Epoch 14/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7590 - val_loss: 0.4260 - val_accuracy: 0.7792\n","Epoch 15/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7720 - val_loss: 0.4252 - val_accuracy: 0.7727\n","Epoch 16/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7720 - val_loss: 0.4227 - val_accuracy: 0.7727\n","Epoch 17/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7687 - val_loss: 0.4209 - val_accuracy: 0.7922\n","Epoch 18/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7687 - val_loss: 0.4198 - val_accuracy: 0.7857\n","Epoch 19/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7720 - val_loss: 0.4190 - val_accuracy: 0.7987\n","Epoch 20/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7720 - val_loss: 0.4186 - val_accuracy: 0.8052\n","Epoch 21/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7736 - val_loss: 0.4180 - val_accuracy: 0.7987\n","Epoch 22/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7769 - val_loss: 0.4179 - val_accuracy: 0.7987\n","Epoch 23/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7687 - val_loss: 0.4166 - val_accuracy: 0.7987\n","Epoch 24/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7720 - val_loss: 0.4149 - val_accuracy: 0.7987\n","Epoch 25/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7769 - val_loss: 0.4155 - val_accuracy: 0.8052\n","Epoch 26/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7720 - val_loss: 0.4153 - val_accuracy: 0.8117\n","Epoch 27/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7752 - val_loss: 0.4150 - val_accuracy: 0.8052\n","Epoch 28/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7704 - val_loss: 0.4146 - val_accuracy: 0.8117\n","Epoch 29/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7736 - val_loss: 0.4138 - val_accuracy: 0.8117\n","Epoch 30/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7720 - val_loss: 0.4144 - val_accuracy: 0.8117\n","Epoch 31/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7769 - val_loss: 0.4130 - val_accuracy: 0.8117\n","Epoch 32/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7769 - val_loss: 0.4121 - val_accuracy: 0.8117\n","Epoch 33/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7818 - val_loss: 0.4119 - val_accuracy: 0.8052\n","Epoch 34/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7883 - val_loss: 0.4117 - val_accuracy: 0.8182\n","Epoch 35/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7801 - val_loss: 0.4103 - val_accuracy: 0.8117\n","Epoch 36/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7785 - val_loss: 0.4105 - val_accuracy: 0.8182\n","Epoch 37/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7769 - val_loss: 0.4104 - val_accuracy: 0.7987\n","Epoch 38/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7785 - val_loss: 0.4101 - val_accuracy: 0.8117\n","Epoch 39/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7818 - val_loss: 0.4119 - val_accuracy: 0.8117\n","Epoch 40/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7850 - val_loss: 0.4123 - val_accuracy: 0.8117\n","Epoch 41/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7834 - val_loss: 0.4118 - val_accuracy: 0.8117\n","Epoch 42/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7850 - val_loss: 0.4111 - val_accuracy: 0.8117\n","Epoch 43/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7818 - val_loss: 0.4111 - val_accuracy: 0.8117\n","Epoch 44/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7818 - val_loss: 0.4116 - val_accuracy: 0.8117\n","Epoch 45/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7932 - val_loss: 0.4113 - val_accuracy: 0.8117\n","Epoch 46/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7883 - val_loss: 0.4102 - val_accuracy: 0.8117\n","Epoch 47/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7850 - val_loss: 0.4111 - val_accuracy: 0.8117\n","Epoch 48/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7883 - val_loss: 0.4112 - val_accuracy: 0.8117\n","Epoch 49/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7932 - val_loss: 0.4106 - val_accuracy: 0.8117\n","Epoch 50/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7883 - val_loss: 0.4107 - val_accuracy: 0.8117\n","Epoch 51/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7915 - val_loss: 0.4100 - val_accuracy: 0.8117\n","Epoch 52/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7866 - val_loss: 0.4095 - val_accuracy: 0.8117\n","Epoch 53/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7915 - val_loss: 0.4095 - val_accuracy: 0.8117\n","Epoch 54/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.4095 - val_accuracy: 0.8117\n","Epoch 55/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.4087 - val_accuracy: 0.8117\n","Epoch 56/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7915 - val_loss: 0.4101 - val_accuracy: 0.8117\n","Epoch 57/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7883 - val_loss: 0.4097 - val_accuracy: 0.8117\n","Epoch 58/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7932 - val_loss: 0.4096 - val_accuracy: 0.8117\n","Epoch 59/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.4094 - val_accuracy: 0.8117\n","Epoch 60/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.4091 - val_accuracy: 0.8117\n","Epoch 61/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8013 - val_loss: 0.4088 - val_accuracy: 0.8117\n","Epoch 62/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7948 - val_loss: 0.4087 - val_accuracy: 0.8117\n","Epoch 63/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7980 - val_loss: 0.4096 - val_accuracy: 0.8052\n","Epoch 64/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7948 - val_loss: 0.4081 - val_accuracy: 0.8117\n","Epoch 65/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7948 - val_loss: 0.4080 - val_accuracy: 0.8117\n","Epoch 66/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7915 - val_loss: 0.4078 - val_accuracy: 0.8117\n","Epoch 67/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.4074 - val_accuracy: 0.8117\n","Epoch 68/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.4083 - val_accuracy: 0.8182\n","Epoch 69/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7899 - val_loss: 0.4090 - val_accuracy: 0.8052\n","Epoch 70/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7980 - val_loss: 0.4087 - val_accuracy: 0.8052\n","Epoch 71/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7948 - val_loss: 0.4085 - val_accuracy: 0.8117\n","Epoch 72/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7915 - val_loss: 0.4079 - val_accuracy: 0.8117\n","Epoch 73/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.7997 - val_loss: 0.4080 - val_accuracy: 0.8052\n","Epoch 74/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7964 - val_loss: 0.4071 - val_accuracy: 0.8117\n","Epoch 75/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8013 - val_loss: 0.4067 - val_accuracy: 0.8117\n","Epoch 76/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7980 - val_loss: 0.4063 - val_accuracy: 0.8117\n","Epoch 77/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7948 - val_loss: 0.4069 - val_accuracy: 0.8117\n","Epoch 78/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.7948 - val_loss: 0.4075 - val_accuracy: 0.8052\n","Epoch 79/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.7980 - val_loss: 0.4062 - val_accuracy: 0.8117\n","Epoch 80/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8013 - val_loss: 0.4079 - val_accuracy: 0.8117\n","Epoch 81/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8029 - val_loss: 0.4071 - val_accuracy: 0.8117\n","Epoch 82/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7980 - val_loss: 0.4069 - val_accuracy: 0.8052\n","Epoch 83/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.7964 - val_loss: 0.4073 - val_accuracy: 0.8052\n","Epoch 84/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.7964 - val_loss: 0.4060 - val_accuracy: 0.8117\n","Epoch 85/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8013 - val_loss: 0.4064 - val_accuracy: 0.8052\n","Epoch 86/100\n","20/20 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8013 - val_loss: 0.4062 - val_accuracy: 0.8117\n","Epoch 87/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8029 - val_loss: 0.4073 - val_accuracy: 0.8052\n","Epoch 88/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8046 - val_loss: 0.4063 - val_accuracy: 0.8117\n","Epoch 89/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.7997 - val_loss: 0.4060 - val_accuracy: 0.8117\n","Epoch 90/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8062 - val_loss: 0.4065 - val_accuracy: 0.8052\n","Epoch 91/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8078 - val_loss: 0.4071 - val_accuracy: 0.8117\n","Epoch 92/100\n","20/20 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8046 - val_loss: 0.4073 - val_accuracy: 0.8117\n","Epoch 93/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8127 - val_loss: 0.4062 - val_accuracy: 0.8117\n","Epoch 94/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8078 - val_loss: 0.4059 - val_accuracy: 0.8117\n","Epoch 95/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8029 - val_loss: 0.4056 - val_accuracy: 0.8117\n","Epoch 96/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8111 - val_loss: 0.4046 - val_accuracy: 0.8052\n","Epoch 97/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8111 - val_loss: 0.4050 - val_accuracy: 0.8052\n","Epoch 98/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8127 - val_loss: 0.4054 - val_accuracy: 0.8182\n","Epoch 99/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8127 - val_loss: 0.4060 - val_accuracy: 0.8117\n","Epoch 100/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8127 - val_loss: 0.4057 - val_accuracy: 0.8182\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2b00a97ca0>"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["# Optimization - rmsprop : loss: 0.4172 - accuracy: 0.7964 - val_loss: 0.4034 - val_accuracy: 0.8117\n","# no. of neuron : 56 -  loss: 0.4060 - accuracy: 0.8127 - val_loss: 0.4057 - val_accuracy: 0.8182"],"metadata":{"id":"wyd4bza7zvc3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# How many hidden layer is required"],"metadata":{"id":"MOa2IXXG0hvT"}},{"cell_type":"code","source":["def build_model(hp):\n","   model = Sequential()\n","   model.add(Dense(56, activation='relu', input_dim = 8))\n","   for i in range(hp.Int('num_of_hidden_layer', min_value=1, max_value=10)):\n","     model.add(Dense(56, activation='relu'))\n","   model.add(Dense(1, activation='sigmoid'))\n","   model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) \n","   return model"],"metadata":{"id":"l5B7Sh5JzVai"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner = kt.RandomSearch(\n","    build_model,\n","    objective='val_accuracy',\n","    max_trials=5, directory='my_dir', project_name='num_of_hidden_layer')"],"metadata":{"id":"bcQ0eknw1A8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner.search(x_train, y_train, validation_data=(x_test, y_test), epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aL5YSYgE1A_j","outputId":"89d4c5e1-886f-436c-db41-e3b4ed61bf56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 5 Complete [00h 00m 03s]\n","val_accuracy: 0.798701286315918\n","\n","Best val_accuracy So Far: 0.8246753215789795\n","Total elapsed time: 00h 00m 10s\n"]}]},{"cell_type":"code","source":["tuner.get_best_hyperparameters()[0].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mN1su8Dh1BCv","outputId":"c1a10967-2f86-4794-9f67-26c1ce6ffa91"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'num_of_hidden_layer': 4}"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["model = tuner.get_best_models(num_models=1)[0]"],"metadata":{"id":"X-sndVvp1BF1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, initial_epoch=6, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iH_MmpV71wyV","outputId":"4921df4c-7bb3-43a5-fa75-aa39ac83bed8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 7/100\n","20/20 [==============================] - 1s 12ms/step - loss: 0.4325 - accuracy: 0.7818 - val_loss: 0.4439 - val_accuracy: 0.7922\n","Epoch 8/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7801 - val_loss: 0.3985 - val_accuracy: 0.8117\n","Epoch 9/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7948 - val_loss: 0.4035 - val_accuracy: 0.8247\n","Epoch 10/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8111 - val_loss: 0.3988 - val_accuracy: 0.8247\n","Epoch 11/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8094 - val_loss: 0.4858 - val_accuracy: 0.7727\n","Epoch 12/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8078 - val_loss: 0.3972 - val_accuracy: 0.8052\n","Epoch 13/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.7997 - val_loss: 0.4219 - val_accuracy: 0.7987\n","Epoch 14/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8241 - val_loss: 0.4189 - val_accuracy: 0.7857\n","Epoch 15/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8355 - val_loss: 0.4248 - val_accuracy: 0.7987\n","Epoch 16/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8306 - val_loss: 0.4229 - val_accuracy: 0.8117\n","Epoch 17/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.8436 - val_loss: 0.4025 - val_accuracy: 0.8052\n","Epoch 18/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8420 - val_loss: 0.4148 - val_accuracy: 0.7987\n","Epoch 19/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8485 - val_loss: 0.3964 - val_accuracy: 0.8312\n","Epoch 20/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8388 - val_loss: 0.4648 - val_accuracy: 0.7727\n","Epoch 21/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.8550 - val_loss: 0.5006 - val_accuracy: 0.7532\n","Epoch 22/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.3246 - accuracy: 0.8550 - val_loss: 0.4409 - val_accuracy: 0.7792\n","Epoch 23/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8827 - val_loss: 0.4137 - val_accuracy: 0.8052\n","Epoch 24/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8730 - val_loss: 0.4163 - val_accuracy: 0.8052\n","Epoch 25/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.8925 - val_loss: 0.4427 - val_accuracy: 0.7792\n","Epoch 26/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.2772 - accuracy: 0.8925 - val_loss: 0.4924 - val_accuracy: 0.7792\n","Epoch 27/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.2820 - accuracy: 0.8876 - val_loss: 0.4555 - val_accuracy: 0.7597\n","Epoch 28/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.2567 - accuracy: 0.8925 - val_loss: 0.4787 - val_accuracy: 0.8052\n","Epoch 29/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.2393 - accuracy: 0.8958 - val_loss: 0.5380 - val_accuracy: 0.7792\n","Epoch 30/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.2418 - accuracy: 0.8990 - val_loss: 0.6303 - val_accuracy: 0.7532\n","Epoch 31/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.2315 - accuracy: 0.9121 - val_loss: 0.5635 - val_accuracy: 0.7273\n","Epoch 32/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.2148 - accuracy: 0.9039 - val_loss: 0.5648 - val_accuracy: 0.7792\n","Epoch 33/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9316 - val_loss: 0.5709 - val_accuracy: 0.7727\n","Epoch 34/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.1946 - accuracy: 0.9251 - val_loss: 0.6257 - val_accuracy: 0.7597\n","Epoch 35/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.2052 - accuracy: 0.9169 - val_loss: 0.6374 - val_accuracy: 0.7403\n","Epoch 36/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.1859 - accuracy: 0.9267 - val_loss: 0.5778 - val_accuracy: 0.7403\n","Epoch 37/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9446 - val_loss: 0.6378 - val_accuracy: 0.7532\n","Epoch 38/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.1702 - accuracy: 0.9349 - val_loss: 0.6734 - val_accuracy: 0.6948\n","Epoch 39/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.1584 - accuracy: 0.9430 - val_loss: 0.7089 - val_accuracy: 0.7078\n","Epoch 40/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9528 - val_loss: 0.6802 - val_accuracy: 0.7338\n","Epoch 41/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.9511 - val_loss: 0.6904 - val_accuracy: 0.7597\n","Epoch 42/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9495 - val_loss: 0.8706 - val_accuracy: 0.7143\n","Epoch 43/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.1412 - accuracy: 0.9511 - val_loss: 0.8817 - val_accuracy: 0.7532\n","Epoch 44/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.1161 - accuracy: 0.9544 - val_loss: 0.7695 - val_accuracy: 0.7338\n","Epoch 45/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.1386 - accuracy: 0.9511 - val_loss: 0.8274 - val_accuracy: 0.7532\n","Epoch 46/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9642 - val_loss: 0.7822 - val_accuracy: 0.7532\n","Epoch 47/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9674 - val_loss: 0.8558 - val_accuracy: 0.6948\n","Epoch 48/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0956 - accuracy: 0.9625 - val_loss: 0.8625 - val_accuracy: 0.7403\n","Epoch 49/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.9609 - val_loss: 1.2293 - val_accuracy: 0.6558\n","Epoch 50/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.9609 - val_loss: 0.8991 - val_accuracy: 0.7597\n","Epoch 51/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9691 - val_loss: 0.9545 - val_accuracy: 0.7597\n","Epoch 52/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9577 - val_loss: 1.1142 - val_accuracy: 0.7403\n","Epoch 53/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9691 - val_loss: 0.9436 - val_accuracy: 0.7338\n","Epoch 54/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9788 - val_loss: 1.1341 - val_accuracy: 0.7273\n","Epoch 55/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9788 - val_loss: 0.9456 - val_accuracy: 0.7208\n","Epoch 56/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9658 - val_loss: 1.0372 - val_accuracy: 0.7143\n","Epoch 57/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9821 - val_loss: 0.9990 - val_accuracy: 0.7468\n","Epoch 58/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9853 - val_loss: 1.0950 - val_accuracy: 0.7468\n","Epoch 59/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 1.2798 - val_accuracy: 0.7273\n","Epoch 60/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9625 - val_loss: 1.0969 - val_accuracy: 0.7403\n","Epoch 61/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9886 - val_loss: 1.1222 - val_accuracy: 0.7662\n","Epoch 62/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9756 - val_loss: 1.3916 - val_accuracy: 0.7078\n","Epoch 63/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9821 - val_loss: 1.2018 - val_accuracy: 0.7532\n","Epoch 64/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9821 - val_loss: 1.1279 - val_accuracy: 0.7662\n","Epoch 65/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9870 - val_loss: 1.1997 - val_accuracy: 0.7338\n","Epoch 66/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9853 - val_loss: 1.1481 - val_accuracy: 0.7273\n","Epoch 67/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9902 - val_loss: 1.2441 - val_accuracy: 0.7662\n","Epoch 68/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9756 - val_loss: 1.1097 - val_accuracy: 0.7727\n","Epoch 69/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9951 - val_loss: 1.4255 - val_accuracy: 0.7338\n","Epoch 70/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9772 - val_loss: 1.1777 - val_accuracy: 0.7597\n","Epoch 71/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.2543 - val_accuracy: 0.7338\n","Epoch 72/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9756 - val_loss: 1.2542 - val_accuracy: 0.7468\n","Epoch 73/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.2766 - val_accuracy: 0.7403\n","Epoch 74/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9707 - val_loss: 1.3453 - val_accuracy: 0.7532\n","Epoch 75/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9886 - val_loss: 1.8192 - val_accuracy: 0.7208\n","Epoch 76/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9886 - val_loss: 1.2508 - val_accuracy: 0.7597\n","Epoch 77/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9919 - val_loss: 1.5116 - val_accuracy: 0.7468\n","Epoch 78/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9935 - val_loss: 1.3379 - val_accuracy: 0.7468\n","Epoch 79/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: 1.5132 - val_accuracy: 0.7403\n","Epoch 80/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9821 - val_loss: 1.3431 - val_accuracy: 0.7403\n","Epoch 81/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 1.4295 - val_accuracy: 0.7792\n","Epoch 82/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9853 - val_loss: 1.2583 - val_accuracy: 0.7727\n","Epoch 83/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9967 - val_loss: 1.4390 - val_accuracy: 0.7208\n","Epoch 84/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 1.3773 - val_accuracy: 0.7468\n","Epoch 85/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 1.6225 - val_accuracy: 0.7273\n","Epoch 86/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9805 - val_loss: 1.4403 - val_accuracy: 0.7532\n","Epoch 87/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9805 - val_loss: 1.5958 - val_accuracy: 0.7273\n","Epoch 88/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9870 - val_loss: 1.3713 - val_accuracy: 0.7532\n","Epoch 89/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 1.4956 - val_accuracy: 0.7727\n","Epoch 90/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9935 - val_loss: 1.3543 - val_accuracy: 0.7792\n","Epoch 91/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9837 - val_loss: 1.4191 - val_accuracy: 0.7727\n","Epoch 92/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4857 - val_accuracy: 0.7662\n","Epoch 93/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9837 - val_loss: 1.5188 - val_accuracy: 0.7403\n","Epoch 94/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 1.5048 - val_accuracy: 0.7468\n","Epoch 95/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 1.5338 - val_accuracy: 0.7468\n","Epoch 96/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 1.6024 - val_accuracy: 0.7468\n","Epoch 97/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9870 - val_loss: 1.4324 - val_accuracy: 0.7532\n","Epoch 98/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 1.3950 - val_accuracy: 0.7727\n","Epoch 99/100\n","20/20 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9967 - val_loss: 1.5800 - val_accuracy: 0.7338\n","Epoch 100/100\n","20/20 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 1.6140 - val_accuracy: 0.7338\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2a9344fbb0>"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":[],"metadata":{"id":"Lt_FfGVL17Tj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cCXGrFzbzVde"},"execution_count":null,"outputs":[]}]}